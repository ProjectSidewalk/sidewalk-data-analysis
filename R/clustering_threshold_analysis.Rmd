---
title: 'Clustering Threshold Analysis'
author: 'Mikey Saugstad'
date: 'December 10, 2017'
output:
  html_document:
    toc: yes
---

```{r setup, include=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
theme_set(theme_bw() + theme(text = element_text(size = 16)))

# Run the following in console when you want to generate github flavored markdown as well.
# library(rmarkdown)
# render('R/clustering_threshold_analysis.Rmd', c('html_document', 'github_document'))
```

## Single-user clustering

```{r reading-cleaning-data-single, include=FALSE, cache=FALSE}
# read in data, it is in a large number of CSV's right now, so read them all in a loop
classes <- c(replicate(6, 'factor'), 'numeric', 'numeric', 'logical', 'logical',
             replicate(3, 'factor'), replicate(8, 'numeric'))

turker.data <- read.csv(paste0('../data/accuracies-turker-0.00000.csv'),
                          colClasses = classes,
                          na.strings = c('null')) %>%
  mutate(threshold = 1000 * 0.00000)

clustered.thresholds <- c(seq(0.00025, 0.01000, 0.00025), seq(0.02000, 0.05000, 0.01000))
clustered.threshold.strings <- format(clustered.thresholds, nsmall = 5)
for (i in seq(1, length(clustered.thresholds))) {
  threshold <- clustered.thresholds[i]
  threshold.string <- format(clustered.threshold.strings[i], nsmall = 5)
  new.data <- read.csv(paste0('../data/accuracies-turker-', threshold.string, '.csv'),
                          colClasses = classes,
                          na.strings = c('null')) %>%
    mutate(threshold = 1000 * threshold)
  turker.data <- bind_rows(turker.data, new.data)
}

# Filter out occlusions labels, compute number of issues per row
turker.data.filtered <-
  turker.data %>%
  filter(!(label.type %in% c('Occlusion', 'NoSidewalk'))) %>%
  # filter(threshold <= 10) %>%
  filter(granularity == '5_meter') %>%
  mutate(issue.count = true.pos + false.pos) %>%
  select(label.type, threshold, issue.count)

# Summarize the data for easier plotting
summarized.by.threshold <-
  turker.data.filtered %>%
  group_by(threshold, label.type) %>%
  summarize_at('issue.count', c('avg.issue.count' = mean, 'issue.count' = sum))

# Grab the count of the max number of issues from the entries where the threshold is 0
max.count <-
  summarized.by.threshold %>%
  filter(threshold == 0)
max.count.vec <- setNames(c(max.count$issue.count), max.count$label.type)
max.avg.vec <- setNames(c(max.count$avg.issue.count), max.count$label.type)

# Compute the percentage of the original for each entry
turker.data.with.percent <-
  turker.data.filtered %>%
  mutate(percent = issue.count / max.avg.vec[as.character(label.type)])
summarized.percentage <-
  summarized.by.threshold %>%
  mutate(percent = 100 * issue.count / max.count.vec[as.character(label.type)])
```

```{r plotting-single, echo=FALSE, cache=FALSE, fig.width=12, fig.height=6}
# Plot line charts to see decrease in labels by label type
ggplot(data = summarized.by.threshold, aes(x = threshold, y = issue.count)) +
  geom_line(aes(colour = label.type)) +
  scale_color_manual(values = c('green', 'red', 'blue', 'orange')) +
  scale_y_continuous(expand = c(0.01,0.01))

# Take a closer look at the percentage of the max issue count, at varying resolutions
create.linechart <- function(data, thresh.max, break.dist, x.intercepts, colors) {
ggplot(data = data, aes(x = threshold, y = percent)) +
  geom_line(aes(colour = label.type)) +
  scale_color_manual(values = colors) +
  scale_x_continuous(breaks = seq(0, thresh.max, break.dist), expand = c(0,0)) +
  geom_vline(xintercept = x.intercepts) +
  scale_y_continuous(expand = c(0.01,0.01))
}
create.linechart(data = summarized.percentage,
                 thresh.max = 50, break.dist = 5, x.intercepts = c(2.5, 7.5),
                 colors = c('green', 'red', 'blue', 'orange'))
create.linechart(data = summarized.percentage %>% filter(threshold < 10),
                 thresh.max = 10, break.dist = 0.5, x.intercepts = 2.5,
                 colors = c('green', 'red', 'blue', 'orange'))
create.linechart(data = summarized.percentage %>%
                   filter(threshold < 3.5) %>%
                   filter(label.type %in% c('CurbRamp', 'NoCurbRamp')),
                 thresh.max = 3.5, break.dist = 0.25, x.intercepts = c(2, 2.5),
                 colors = c('green', 'red'))
create.linechart(data = summarized.percentage %>%
                   filter(threshold < 10) %>%
                   filter(label.type %in% c('Obstacle', 'SurfaceProblem')),
                 thresh.max = 10, break.dist = 0.5, x.intercepts = 7.5,
                 colors = c('blue', 'orange'))

```

## Multi-user clustering

```{r reading-cleaning-data-multi, include=FALSE, cache=FALSE}
# read in data, it is in a large number of CSV's right now, so read them all in a loop
classes <- c(replicate(6, 'factor'), 'numeric', 'numeric', 'logical', 'logical',
             replicate(3, 'factor'), replicate(8, 'numeric'))

cluster.data1 <- read.csv(paste0('../data/accuracies-turker-3-0.00000.csv'),
                          colClasses = classes,
                          na.strings = c('null')) %>%
  mutate(threshold = 1000 * 0.00000)
cluster.data2 <- read.csv(paste0('../data/accuracies-turker-5-0.00000.csv'),
                          colClasses = classes,
                          na.strings = c('null')) %>%
  mutate(threshold = 1000 * 0.00000)
cluster.data <- bind_rows(cluster.data1, cluster.data2)

# clustered.thresholds <- seq(0.00100, 0.01200, 0.00100)
clustered.thresholds <- seq(0.00100, 0.05000, 0.00100)
clustered.threshold.strings <- format(clustered.thresholds, nsmall = 5)
for (i in seq(1, length(clustered.thresholds))) {
  threshold <- clustered.thresholds[i]
  threshold.string <- format(clustered.threshold.strings[i], nsmall = 5)
  new.data1 <- read.csv(paste0('../data/accuracies-turker-3-', threshold.string, '.csv'),
                          colClasses = classes,
                          na.strings = c('null')) %>%
    mutate(threshold = 1000 * threshold)
  new.data2 <- read.csv(paste0('../data/accuracies-turker-5-', threshold.string, '.csv'),
                          colClasses = classes,
                          na.strings = c('null')) %>%
    mutate(threshold = 1000 * threshold)
  cluster.data <- bind_rows(cluster.data, new.data1, new.data2)
  # cluster.data <- bind_rows(cluster.data, new.data1)
}

cluster.data.filtered <-
  cluster.data %>%
  filter(!(label.type %in% c('Occlusion', 'NoSidewalk'))) %>%
  filter(granularity == '5_meter') %>%
  mutate(issue.count = true.pos + false.pos) %>%
  select(label.type, threshold, issue.count, n.workers, worker.thresh, binary)
  
cluster.data.filtered <-
  cluster.data.filtered %>%
  filter(binary == FALSE) %>%
  select(-binary)

# add column for vote threshold
get.threshold.factor <- Vectorize(
    function(workers, threshold) {
    if (threshold == 1) 'at.least.one'
    else if (workers == threshold) 'consensus'
    else 'majority'
  }
)
with.vote <-
  cluster.data.filtered %>%
  mutate(vote.threshold = ordered(get.threshold.factor(n.workers, worker.thresh),
                                  levels = c('at.least.one', 'majority', 'consensus')))

# Summarize the data for easier plotting
cluster.summarized.by.threshold <-
  with.vote %>%
  group_by(threshold, label.type, n.workers, vote.threshold) %>%
  summarize_at('issue.count', c('avg.issue.count' = mean, 'issue.count' = sum))

# Grab the count of the max number of issues from the entries where the threshold is 0
cluster.max.count <-
  cluster.summarized.by.threshold %>%
  group_by(label.type, n.workers, vote.threshold) %>%
  summarize_at(c('issue.count', 'avg.issue.count'), max) %>%
  rename(max.count = issue.count, max.avg = avg.issue.count)

# Compute the percentage of the original for each entry
cluster.summarized.percentage <-
  cluster.summarized.by.threshold %>%
  inner_join(cluster.max.count, by = c('label.type', 'n.workers', 'vote.threshold')) %>%
  mutate(percent = 100 * issue.count / max.count)
```

This graph shows the percent of the max number of issues/features of that issue/feature type at varying clustering thresholds. The plots are split by voting procedure and number of turkers, with a line for each label type in each subplot. By "percent of the max...", I mean that within that group (where we grouped by voting procedure, number of turkers, and label type), the max number of issues/features found across all thresholds. I placed a vertical line at 7.5 meters, which is the distance that we have been using as our clustering threshold before this analysis.

For the "at least one" voting procedure, the number of issues/features is monotonically decreasing, and this will always be the case. At a threshold of 0, all the labels are their own issue/feature, then labels get collapsed into clusters as you increase the threshold, reducing the number of issues/features.

For consensus, there are so few agreed upon labels for the SurfaceProblem label type (and also the Obstacle and NoCurbRamp label types, just in the case of 5 turkers), that there isn't much to gain from looking at the graph. We shouldn't be using the consensus graph to help us determine what threshold to use, since we almost certainly won't use that in practice (false positives are much easier to fix than false negatives).

When looking at majority vote, we see that at a threshold of 5 meters, we hit about 80% of the max number of curb ramps, and 70% of the max number of missing curb ramps, with much slower growth after that. For the other label types, we see a steeper slope during the first 5-8 than at higher thresholds, though the slope is definitely steeper at higher thresholds for these label types than for the ramp types.

```{r plotting-multi, echo=FALSE, cache=FALSE, fig.width=12, fig.height=8}
ggplot(data = cluster.summarized.percentage, aes(x = threshold, y = percent)) +
  geom_line(aes(colour = label.type)) +
  scale_color_manual(values = c('green', 'red', 'blue', 'orange')) +
  scale_x_continuous(breaks = seq(0, 50, 5), expand = c(0,0)) +
  geom_vline(xintercept = 7.5) +
  scale_y_continuous(expand = c(0.01,0.01)) +
  facet_grid(n.workers ~ vote.threshold)

# ggplot(data = cluster.summarized.by.threshold %>%
#          filter(!(label.type %in% c('CurbRamp', 'NoCurbRamp'))) %>%
#          filter(vote.threshold == 'consensus'),
#        aes(x = threshold, y = issue.count)) +
#   geom_line(aes(colour = label.type)) +
#   scale_color_manual(values = c('blue', 'orange')) +
#   scale_x_continuous(breaks = seq(0, 38, 5), expand = c(0,0)) +
#   geom_vline(xintercept = 7.5) +
#   scale_y_continuous(expand = c(0.01,0.01)) +
#   facet_grid(n.workers ~ ., scales = 'free_y')
# 
# ggplot(data = cluster.summarized.by.threshold %>%
#          filter(!(label.type %in% c('CurbRamp', 'NoCurbRamp'))) %>%
#          filter(vote.threshold == 'majority'),
#        aes(x = threshold, y = issue.count)) +
#   geom_line(aes(colour = label.type)) +
#   scale_color_manual(values = c('blue', 'orange')) +
#   scale_x_continuous(breaks = seq(0, 38, 5), expand = c(0,0)) +
#   geom_vline(xintercept = 7.5) +
#   scale_y_continuous(expand = c(0.01,0.01)) +
#   facet_grid(n.workers ~ ., scales = 'free_y')

```
