---
title: "Statistics for Paper"
author: "Mikey Saugstad"
date: "March 19, 2018"
output:
  html_document:
    toc: yes
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(RPostgreSQL)
library(ggplot2)
library(tidyr)
library(dplyr)

# Run the following in console when you want to generate github flavored markdown as well.
# library(rmarkdown)
# render('R/stats_for_paper.Rmd', c('html_document', 'github_document'))

# If true, queries local postges database for data (could take a very long time), then saves in
# CSVs, so you should set to FALSE after running with the actual queries once.
REFRESH_DATA = FALSE
LABEL_TYPE_MAPPING <- c(
  '1' = 'CurbRamp',
  '2' = 'NoCurbRamp',
  '3' = 'Obstacle',
  '4' = 'SurfaceProblem',
  '5' = 'Other',
  '6' = 'Occlusion',
  '7' = 'NoSidewalk'
)
TOTAL_STREET_DIST_METERS <- 1730179
TOTAL_STREET_DIST_MILES <- TOTAL_STREET_DIST_METERS / 1609.34
```

```{r connect, echo=FALSE}
if (REFRESH_DATA) {
  pw <- {'sidewalk'}
  drv <- dbDriver("PostgreSQL")
  con <- dbConnect(drv, dbname = "sidewalk",
                   host = "localhost", port = 5432,
                   user = "sidewalk", password = pw)
  rm(pw)
}
```


```{r reading.data, echo=FALSE, include=FALSE}
if (REFRESH_DATA) {
  reg.labels <-
    dbGetQuery(
      con,
      'SELECT label_id, user_id, label_type_id, audit_task.audit_task_id
      FROM audit_task
      INNER JOIN label
      ON audit_task.audit_task_id = label.audit_task_id
      WHERE label.deleted = FALSE
      AND user_id <> \'97760883-8ef0-4309-9a5e-0c086ef27573\'
      AND completed = TRUE'
      )
  anon.labels <-
    dbGetQuery(
      con,
      'SELECT DISTINCT label_id, ip_address AS user_id, label_type_id, audit_task.audit_task_id
      FROM audit_task
      INNER JOIN label
      ON audit_task.audit_task_id = label.audit_task_id
      INNER JOIN audit_task_environment
      ON audit_task.audit_task_id = audit_task_environment.audit_task_id
      WHERE label.deleted = FALSE
      AND user_id = \'97760883-8ef0-4309-9a5e-0c086ef27573\'
      AND completed = TRUE'
      )
  reg.audits <-
    dbGetQuery(
      con,
      'SELECT audit_task.user_id, role.role, audit_task.audit_task_id,
              street_edge.street_edge_id,
              ST_LENGTH(ST_TRANSFORM(geom,26918)) * 3.28084 AS feet_audited
      FROM street_edge
      INNER JOIN audit_task
      ON street_edge.street_edge_id = audit_task.street_edge_id
      INNER JOIN user_role
      ON audit_task.user_id = user_role.user_id
      INNER JOIN role
      ON user_role.role_id = role.role_id
      WHERE street_edge.deleted = FALSE
      AND audit_task.user_id <> \'97760883-8ef0-4309-9a5e-0c086ef27573\'
      AND completed = TRUE'
      )
  anon.audits <-
    dbGetQuery(
      con,
      'SELECT DISTINCT ip_address AS user_id, \'Anonymous\' AS role, audit_task.audit_task_id,
              street_edge.street_edge_id,
              ST_LENGTH(ST_TRANSFORM(geom,26918)) * 3.28084 AS feet_audited
      FROM street_edge
      INNER JOIN audit_task
      ON street_edge.street_edge_id = audit_task.street_edge_id
      INNER JOIN audit_task_environment
      ON audit_task.audit_task_id = audit_task_environment.audit_task_id
      WHERE street_edge.deleted = FALSE
      AND user_id = \'97760883-8ef0-4309-9a5e-0c086ef27573\'
      AND completed = TRUE'
      )
  reg.times <-
    dbGetQuery(
      con,
      'SELECT user_audit_times.user_id,
             CAST(extract( second from SUM(diff) ) / 60 +
                  extract( minute from SUM(diff) ) +
                  extract( hour from SUM(diff) ) * 60 AS decimal(10,2)) AS minutes_audited
      FROM (
          SELECT audit_task.user_id,
                 (timestamp - LAG(timestamp, 1) OVER(PARTITION BY user_id ORDER BY timestamp)) AS diff
          FROM audit_task_interaction
          INNER JOIN audit_task ON audit_task.audit_task_id = audit_task_interaction.audit_task_id
          WHERE action = \'ViewControl_MouseDown\'
              AND audit_task.user_id <> \'97760883-8ef0-4309-9a5e-0c086ef27573\'
          ) user_audit_times
      WHERE diff < \'00:05:00.000\' AND diff > \'00:00:00.000\'
      GROUP BY user_audit_times.user_id;'
      )
  anon.times <-
    dbGetQuery(
      con,
      'SELECT user_audit_times.ip_address AS user_id,
             CAST(extract( second from SUM(diff) ) /60 +
                  extract( minute from SUM(diff) ) +
                  extract( hour from SUM(diff) ) * 60 AS decimal(10,2)) AS minutes_audited
      FROM
      (
          SELECT user_id, ip_address,
                 (timestamp - Lag(timestamp, 1) OVER(PARTITION BY user_id ORDER BY timestamp)) AS diff
          FROM audit_task_interaction
          INNER JOIN audit_task ON audit_task.audit_task_id = audit_task_interaction.audit_task_id
          INNER JOIN audit_task_environment
              ON audit_task.audit_task_id = audit_task_environment.audit_task_id
          WHERE action = \'ViewControl_MouseDown\'
          AND audit_task.user_id = \'97760883-8ef0-4309-9a5e-0c086ef27573\'
          AND ip_address IN
          (
              SELECT ip_address
              FROM audit_task_environment
              INNER JOIN audit_task ON audit_task.audit_task_id = audit_task_environment.audit_task_id
              WHERE completed = true
          )
      ) user_audit_times
      WHERE diff < \'00:05:00.000\' AND diff > \'00:00:00.000\'
      GROUP BY ip_address;'
      )
  reg.missions <-
    dbGetQuery(
      con,
      'SELECT "user".user_id, COALESCE(count, 0) AS mission_count
      FROM "user"
      LEFT JOIN
      (
        SELECT "user".user_id, COUNT(mission_user_id)
        FROM "user"
        INNER JOIN mission_user
        ON "user".user_id = mission_user.user_id
        GROUP BY "user".user_id
      ) "nonzero_counts"
      ON nonzero_counts.user_id = "user".user_id
      WHERE "user".user_id <> \'97760883-8ef0-4309-9a5e-0c086ef27573\''
      )
  dbDisconnect(con)
  
  audits <- bind_rows(reg.audits, anon.audits)
  times <- bind_rows(reg.times, anon.times)
  labels <- bind_rows(reg.labels, anon.labels)
  write.csv(audits, '../data/stats_for_paper_audits.csv', row.names = FALSE)
  write.csv(times, '../data/stats_for_paper_times.csv', row.names = FALSE)
  write.csv(labels, '../data/stats_for_paper_labels.csv', row.names = FALSE)
  write.csv(reg.missions, '../data/stats_for_paper_reg_missions.csv', row.names = FALSE)
} else {
  audit.classes <- c('character', 'character', 'numeric', 'numeric', 'numeric')
  audits <- read.csv('../data/stats_for_paper_audits.csv', colClasses = audit.classes)
  time.classes <- c('character', 'numeric')
  times <- read.csv('../data/stats_for_paper_times.csv', colClasses = time.classes)
  label.classes <- c('numeric', 'character', 'numeric', 'numeric')
  labels <- read.csv('../data/stats_for_paper_labels.csv', colClasses = label.classes)
  mission.classes <- c('character', 'numeric')
  reg.missions <- read.csv('../data/stats_for_paper_reg_missions.csv', colClasses = mission.classes)
}
```

```{r transforming.data, echo=FALSE, warning=FALSE}
# Takes a distance in feet and approximates the number of missions the user completed. The
# approximation assumes that the first missions are 500, 500, 1000, 2000, and 1280 feet, and all the
# remaining missions are half a mile (2640 feet).
approximate.missions.completed <- Vectorize(
  function(dist.in.feet) {
    if (dist.in.feet > 7920) 5 + floor((dist.in.feet - 5280) / 2640)
    else if (dist.in.feet > 5280) 5
    else if (dist.in.feet > 4000) 4
    else if (dist.in.feet > 2000) 3
    else if (dist.in.feet > 1000) 2
    else if (dist.in.feet > 500) 1
    else 0
  }
)

# Computes minutes_per_mission as either minutes_audited / missions_completed if at least one
# mission was completed, other wise 500 * minutes_audited / feet_audited (how long the first mission
# would take, given the auditing speed for what they had done)
approximate.minutes.per.mission <- Vectorize(
  function(time.audited, missions.completed, dist.in.feet) {
    if (missions.completed > 0) time.audited / missions.completed
    else 500 * time.audited / dist.in.feet
  }
)

label.counts <-
  labels %>%
  # filter(label_type_id != 7) %>%
  group_by(user_id) %>%
  summarize_at(vars(label_id), n_distinct) %>%
  rename(label_count = label_id)

# Selects distinct on audit_task_id, then sums dist audited.
audit.length <-
  audits %>%
  mutate(role = factor(role),
         role = recode(role, User = 'Registered', .default = levels(role))) %>%
  group_by(user_id, role) %>%
  distinct(audit_task_id, .keep_all = TRUE) %>%
  summarise(feet_audited = sum(feet_audited), audit_count = n()) %>%
  ungroup() %>%
  mutate(miles_audited = feet_audited / 5280) %>%
  left_join(label.counts, by = 'user_id') %>%
  replace_na(list(label_count = 0)) %>%
  mutate(labels_per_100m = 328.084 * label_count / feet_audited)

# Computes approximate missions completed for anon users.
all.mission.counts <-
  audit.length %>%
  filter(role == "Anonymous") %>%
  mutate(mission_count = approximate.missions.completed(feet_audited)) %>%
  select(user_id, mission_count) %>%
  bind_rows(reg.missions)

# Computes a few metrics based on distance audited, time auditing, and missions completed.
speeds <-
  audit.length %>%
  left_join(all.mission.counts, by = 'user_id') %>%
  left_join(times, by = 'user_id') %>%
  mutate(feet_per_min = feet_audited / minutes_audited,
         minutes_per_mission = approximate.minutes.per.mission(minutes_audited, mission_count, feet_audited),
         minutes_per_1k_ft = 1000 * minutes_audited / feet_audited,
         hours_audited = minutes_audited / 60)

filtered.speeds <-
  speeds %>%
  filter(role %in% c('Registered', 'Anonymous', 'Turker'),
         labels_per_100m >= 3.75)
```

## Public Deployment

NOTE: The public deployment dataset being used right now is not all that recent, so do not draw conclusions from what is below right now.

### Top-line numbers (no filtering)

Note that this is the only section for the public deployment where we are not filtering out users below the labeling frequency threshold (I am also filtering out researcher data below for now).

TODO: anything else?

```{r how.much.data, echo=FALSE, warning=FALSE}
kable(
  labels %>%
    count(label_type_id) %>%
    mutate(label_type = LABEL_TYPE_MAPPING[label_type_id]) %>%
    select(label_type, n) %>%
    bind_rows(list(label_type = 'Total', n = nrow(labels))) %>%
    spread(label_type, n),
  align = 'l'
)
```

### Data characteristics

This is the start of filtering out users with low labeling frequency (also filtering out researchers).

TODO: anything else?

```{r data.characteristics, echo=FALSE, warning=FALSE}
filtered.labels <- filter(labels, user_id %in% filtered.speeds$user_id)
kable(
  filtered.labels %>%
    count(label_type_id) %>%
    mutate(label_type = LABEL_TYPE_MAPPING[label_type_id]) %>%
    select(label_type, n) %>%
    bind_rows(list(label_type = 'Total', n = nrow(filtered.labels))) %>%
    spread(label_type, n),
  align = 'l'
)

filtered.audits <- filter(audits, user_id %in% filtered.speeds$user_id)
n.audits <- nrow(filtered.audits)
n.streets <- n_distinct(filtered.audits$street_edge_id)
```

There have been a total of `r n.audits` audits by our users across `r n.streets` streets, averaging `r format(n.audits/n.streets, digits = 3)` audits per street.

### User stats and tool usage

TODO: coverage for each user group<br>
TODO: how long users stay on tool (use same method as computing total time spent, just with bigger time difference)<br>
TODO: missions started vs missions completed (not sure we can do this; I expect that it would be difficult, without much benefit)

Below are the medians for a few metrics (followed by sums), split by user group. For all user groups, the minimum threshold to be included in this list was that they have completed at least one audit task and that their labeling threshold is above 3.75 labels per 100 meters.

```{r showing.stats, echo=FALSE, warning=FALSE}
kable(
  filtered.speeds %>%
    group_by(role) %>%
    summarise(
      n_users = n(),
      miles = median(miles_audited, na.rm = TRUE),
      missions = median(mission_count, na.rm = TRUE),
      audits = median(audit_count, na.rm = TRUE),
      minutes_audited = median(minutes_audited, na.rm = TRUE),
      minutes_per_1k_ft = median(minutes_per_1k_ft, na.rm = TRUE),
      labels = median(label_count, na.rm = TRUE),
      labels_per_100m = median(labels_per_100m, na.rm = TRUE)
      ),
  digits = 3,
  align = 'l'
  )

kable(
  filtered.speeds %>%
    group_by(role) %>%
    summarise(
      n_users = n(),
      miles = sum(miles_audited, na.rm = TRUE),
      coverage = paste0(format(100 * sum(miles_audited, na.rm = TRUE) / TOTAL_STREET_DIST_MILES,
                               digits = 2),
                        '%'),
      missions = sum(mission_count, na.rm = TRUE),
      audits = sum(audit_count, na.rm = TRUE),
      hours_audited = sum(hours_audited, na.rm = TRUE),
      labels = sum(label_count, na.rm = TRUE)
      ),
  digits = 3,
  align = 'l'
  )
```

### Possible Story 1: Data overlap and agreement between users

Amongst all the data collected in DC, how much of DC is labeled by multiple users and what is the disagreement amongst them? (see comment in Outline document for details on implementation)

## Turk Study
