---
title: "Statistics for Paper"
author: "Mikey Saugstad"
date: "April 3, 2018"
output:
  html_document:
    toc: yes
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(RPostgreSQL)
library(ggplot2)
library(tidyr)
library(dplyr)

# Run the following in console when you want to generate github flavored markdown as well.
# library(rmarkdown)
# render('R/stats_for_paper.Rmd', c('html_document', 'github_document'))

# If true, queries local postges database for data (could take a very long time), then saves in
# CSVs, so you should set to FALSE after running with the actual queries once.
REFRESH_PUBLIC_DEPLOYMENT_DATA = FALSE
REFRESH_TURK_STUDY_DATA = FALSE

LABEL_TYPE_MAPPING <- c(
  '1' = 'CurbRamp',
  '2' = 'NoCurbRamp',
  '3' = 'Obstacle',
  '4' = 'SurfaceProblem',
  '5' = 'Other',
  '6' = 'Occlusion',
  '7' = 'NoSidewalk'
)
TOTAL_STREET_DIST_METERS <- 1730179
TOTAL_STREET_DIST_MILES <- TOTAL_STREET_DIST_METERS / 1609.34

my.theme.discrete.x <- theme_bw() + theme(panel.grid.major.x = element_blank())
```

```{r connect, echo=FALSE}
if (REFRESH_PUBLIC_DEPLOYMENT_DATA | REFRESH_TURK_STUDY_DATA) drv <- dbDriver("PostgreSQL")
if (REFRESH_PUBLIC_DEPLOYMENT_DATA) {
  db.connection.public.deployment <- dbConnect(drv, dbname = "sidewalk",
                   host = "localhost", port = 5432,
                   user = "sidewalk", password = 'sidewalk')
}
if (REFRESH_TURK_STUDY_DATA) {
  db.connection.turk.study <- dbConnect(drv, dbname = "sidewalkturk",
                   host = "localhost", port = 5432,
                   user = "sidewalk", password = 'sidewalk')
  db.connection.turk.study.production <- dbConnect(drv, dbname = "sidewalk-volunteer-gt",
                   host = "localhost", port = 5432,
                   user = "sidewalk", password = 'sidewalk')
}
```


```{r reading.data, echo=FALSE, include=FALSE}
if (REFRESH_PUBLIC_DEPLOYMENT_DATA) {
  reg.labels <-
    dbGetQuery(
      db.connection.public.deployment,
      'SELECT label_id, user_id, label_type_id, audit_task.audit_task_id
      FROM audit_task
      INNER JOIN label
      ON audit_task.audit_task_id = label.audit_task_id
      WHERE label.deleted = FALSE
      AND user_id <> \'97760883-8ef0-4309-9a5e-0c086ef27573\''
      )
  anon.labels <-
    dbGetQuery(
      db.connection.public.deployment,
      'SELECT DISTINCT label_id, ip_address AS user_id, label_type_id, audit_task.audit_task_id
      FROM audit_task
      INNER JOIN label
      ON audit_task.audit_task_id = label.audit_task_id
      INNER JOIN audit_task_environment
      ON audit_task.audit_task_id = audit_task_environment.audit_task_id
      WHERE label.deleted = FALSE
      AND user_id = \'97760883-8ef0-4309-9a5e-0c086ef27573\''
      )
  reg.audits <-
    dbGetQuery(
      db.connection.public.deployment,
      'SELECT audit_task.user_id, role.role, audit_task.audit_task_id,
              street_edge.street_edge_id,
              ST_LENGTH(ST_TRANSFORM(geom,26918)) * 3.28084 AS feet_audited
      FROM street_edge
      INNER JOIN audit_task
      ON street_edge.street_edge_id = audit_task.street_edge_id
      INNER JOIN user_role
      ON audit_task.user_id = user_role.user_id
      INNER JOIN role
      ON user_role.role_id = role.role_id
      WHERE street_edge.deleted = FALSE
      AND audit_task.user_id <> \'97760883-8ef0-4309-9a5e-0c086ef27573\'
      AND completed = TRUE'
      )
  anon.audits <-
    dbGetQuery(
      db.connection.public.deployment,
      'SELECT DISTINCT ip_address AS user_id, \'Anonymous\' AS role, audit_task.audit_task_id,
              street_edge.street_edge_id,
              ST_LENGTH(ST_TRANSFORM(geom,26918)) * 3.28084 AS feet_audited
      FROM street_edge
      INNER JOIN audit_task
      ON street_edge.street_edge_id = audit_task.street_edge_id
      INNER JOIN audit_task_environment
      ON audit_task.audit_task_id = audit_task_environment.audit_task_id
      WHERE street_edge.deleted = FALSE
      AND user_id = \'97760883-8ef0-4309-9a5e-0c086ef27573\'
      AND completed = TRUE'
      )
  reg.times <-
    dbGetQuery(
      db.connection.public.deployment,
      'SELECT user_audit_times.user_id,
             CAST(extract( second from SUM(diff) ) / 60 +
                  extract( minute from SUM(diff) ) +
                  extract( hour from SUM(diff) ) * 60 AS decimal(10,2)) AS minutes_audited
      FROM
      (
          SELECT audit_task.user_id,
                 (timestamp - LAG(timestamp, 1) OVER(PARTITION BY user_id ORDER BY timestamp)) AS diff
          FROM audit_task_interaction
          INNER JOIN audit_task ON audit_task.audit_task_id = audit_task_interaction.audit_task_id
          WHERE action = \'ViewControl_MouseDown\'
              AND audit_task.user_id <> \'97760883-8ef0-4309-9a5e-0c086ef27573\'
          ) user_audit_times
      WHERE diff < \'00:05:00.000\' AND diff > \'00:00:00.000\'
      GROUP BY user_audit_times.user_id;'
      )
  anon.times <-
    dbGetQuery(
      db.connection.public.deployment,
      'SELECT user_audit_times.ip_address AS user_id,
             CAST(extract( second from SUM(diff) ) /60 +
                  extract( minute from SUM(diff) ) +
                  extract( hour from SUM(diff) ) * 60 AS decimal(10,2)) AS minutes_audited
      FROM
      (
          SELECT user_id, ip_address,
                 (timestamp - Lag(timestamp, 1) OVER(PARTITION BY user_id ORDER BY timestamp)) AS diff
          FROM audit_task_interaction
          INNER JOIN audit_task ON audit_task.audit_task_id = audit_task_interaction.audit_task_id
          INNER JOIN audit_task_environment
              ON audit_task.audit_task_id = audit_task_environment.audit_task_id
          WHERE action = \'ViewControl_MouseDown\'
          AND audit_task.user_id = \'97760883-8ef0-4309-9a5e-0c086ef27573\'
          AND ip_address IN
          (
              SELECT ip_address
              FROM audit_task_environment
              INNER JOIN audit_task ON audit_task.audit_task_id = audit_task_environment.audit_task_id
              WHERE completed = true
          )
      ) user_audit_times
      WHERE diff < \'00:05:00.000\' AND diff > \'00:00:00.000\'
      GROUP BY ip_address;'
      )
  reg.sessions <-
    dbGetQuery(
      db.connection.public.deployment,
      'SELECT "user".user_id, 1 + COALESCE(n_sessions_minus_one, 0) AS n_sessions
      FROM
      (
          SELECT user_audit_times.user_id, COUNT(diff) AS n_sessions_minus_one
          FROM
          (
              SELECT audit_task.user_id,
                     (timestamp - LAG(timestamp, 1) OVER(PARTITION BY user_id ORDER BY timestamp)) AS diff
              FROM audit_task_interaction
              INNER JOIN audit_task ON audit_task.audit_task_id = audit_task_interaction.audit_task_id
              WHERE action = \'ViewControl_MouseDown\'
                  AND audit_task.user_id <> \'97760883-8ef0-4309-9a5e-0c086ef27573\'
          ) user_audit_times
          WHERE diff > \'01:00:00.000\'
          GROUP BY user_audit_times.user_id
      ) sess_counts
      RIGHT JOIN "user" ON sess_counts.user_id = "user".user_id;'
      )
  anon.sessions <-
    dbGetQuery(
      db.connection.public.deployment,
      'SELECT ips.ip_address AS user_id, 1 + COALESCE(n_sessions_minus_one, 0) AS n_sessions
      FROM
      (
          SELECT DISTINCT(ip_address) FROM audit_task_environment
      ) ips
      LEFT JOIN
      (
          SELECT user_audit_times.ip_address, COUNT(diff) AS n_sessions_minus_one
          FROM
          (
              SELECT user_id,
                     ip_address,
                     (timestamp - Lag(timestamp, 1) OVER(PARTITION BY user_id ORDER BY timestamp)) AS diff
              FROM audit_task_interaction
              INNER JOIN audit_task ON audit_task.audit_task_id = audit_task_interaction.audit_task_id
              INNER JOIN audit_task_environment
                  ON audit_task.audit_task_id = audit_task_environment.audit_task_id
              WHERE action = \'ViewControl_MouseDown\'
              AND audit_task.user_id = \'97760883-8ef0-4309-9a5e-0c086ef27573\'
              AND ip_address IN
              (
                  SELECT ip_address
                  FROM audit_task_environment
                  INNER JOIN audit_task ON audit_task.audit_task_id = audit_task_environment.audit_task_id
                  WHERE completed = true
              )
          ) user_audit_times
          WHERE diff > \'01:00:00.000\'
          GROUP BY ip_address
      ) sess_counts
      ON ips.ip_address = sess_counts.ip_address;'
      )
  reg.missions <-
    dbGetQuery(
      db.connection.public.deployment,
      'SELECT "user".user_id, COALESCE(count, 0) AS mission_count
      FROM "user"
      LEFT JOIN
      (
        SELECT "user".user_id, COUNT(mission_user_id)
        FROM "user"
        INNER JOIN mission_user
        ON "user".user_id = mission_user.user_id
        GROUP BY "user".user_id
      ) "nonzero_counts"
      ON nonzero_counts.user_id = "user".user_id
      WHERE "user".user_id <> \'97760883-8ef0-4309-9a5e-0c086ef27573\''
      )
  dbDisconnect(db.connection.public.deployment)
  
  audits <- bind_rows(reg.audits, anon.audits)
  times <- bind_rows(reg.times, anon.times)
  labels <- bind_rows(reg.labels, anon.labels)
  sessions <- bind_rows(reg.sessions, anon.sessions)
  write.csv(audits, '../data/stats_for_paper_audits.csv', row.names = FALSE)
  write.csv(times, '../data/stats_for_paper_times.csv', row.names = FALSE)
  write.csv(labels, '../data/stats_for_paper_labels.csv', row.names = FALSE)
  write.csv(sessions, '../data/stats_for_paper_sessions.csv', row.names = FALSE)
  write.csv(reg.missions, '../data/stats_for_paper_reg_missions.csv', row.names = FALSE)
} else {
  audit.classes <- c('character', 'character', 'numeric', 'numeric', 'numeric')
  audits <- read.csv('../data/stats_for_paper_audits.csv', colClasses = audit.classes)
  time.classes <- c('character', 'numeric')
  times <- read.csv('../data/stats_for_paper_times.csv', colClasses = time.classes)
  label.classes <- c('numeric', 'character', 'numeric', 'numeric')
  labels <- read.csv('../data/stats_for_paper_labels.csv', colClasses = label.classes)
  session.classes <- c('character', 'numeric')
  sessions <- read.csv('../data/stats_for_paper_sessions.csv', colClasses = session.classes)
  mission.classes <- c('character', 'numeric')
  reg.missions <- read.csv('../data/stats_for_paper_reg_missions.csv', colClasses = mission.classes)
}


if (REFRESH_TURK_STUDY_DATA) {
  reg.labels.turk.study <-
    dbGetQuery(
      db.connection.turk.study.production,
      'SELECT label_id, user_id, label_type_id, audit_task.audit_task_id, amt_condition_id AS condition_id
      FROM amt_condition
      INNER JOIN amt_volunteer_route ON amt_condition.volunteer_id = amt_volunteer_route.volunteer_id
      INNER JOIN route_street ON amt_volunteer_route.route_id = route_street.route_id
      INNER JOIN audit_task ON  route_street.current_street_edge_id = audit_task.street_edge_id
                            AND amt_volunteer_route.volunteer_id = audit_task.user_id
      INNER JOIN label ON audit_task.audit_task_id = label.audit_task_id
      WHERE amt_condition.amt_condition_id NOT IN (71, 104, 105, 123, 124, 130, 138)
      AND label.deleted <> TRUE'
      )
  anon.labels.turk.study <-
    dbGetQuery(
      db.connection.turk.study.production,
      'SELECT DISTINCT label_id, audit_task_environment.ip_address AS user_id, label_type_id,
                       audit_task.audit_task_id, amt_condition_id AS condition_id
      FROM amt_condition
      INNER JOIN amt_volunteer_route ON amt_condition.volunteer_id = amt_volunteer_route.volunteer_id
      INNER JOIN route_street ON amt_volunteer_route.route_id = route_street.route_id
      INNER JOIN audit_task ON  route_street.current_street_edge_id = audit_task.street_edge_id
      INNER JOIN audit_task_environment ON  audit_task.audit_task_id = audit_task_environment.audit_task_id
                                        AND amt_volunteer_route.ip_address = audit_task_environment.ip_address
      INNER JOIN label ON audit_task.audit_task_id = label.audit_task_id
      WHERE amt_condition.amt_condition_id NOT IN (71, 104, 105, 123, 124, 130, 138)
      AND label.deleted <> TRUE'
      )
  turk.labels.turk.study <-
    dbGetQuery(
      db.connection.turk.study,
      'SELECT label_id, turker_id AS user_id, label_type_id, audit_task.audit_task_id, condition_id
      FROM amt_assignment
      INNER JOIN audit_task ON amt_assignment.amt_assignment_id = audit_task.amt_assignment_id
      INNER JOIN label ON audit_task.audit_task_id = label.audit_task_id
      WHERE amt_assignment.condition_id NOT IN (71, 104, 105, 123, 124, 130, 138)
      AND label.deleted <> TRUE'
      )
  reg.times.turk.study <-
    dbGetQuery(
      db.connection.turk.study.production,
      'SELECT user_audit_times.user_id,
             CAST(extract( second from SUM(diff) ) / 60 +
                  extract( minute from SUM(diff) ) +
                  extract( hour from SUM(diff) ) * 60 AS decimal(10,2)) AS minutes_audited
      FROM
      (
          SELECT audit_task.user_id,
                 (timestamp - LAG(timestamp, 1) OVER(PARTITION BY user_id ORDER BY timestamp)) AS diff
          FROM amt_condition
          INNER JOIN amt_volunteer_route ON amt_condition.volunteer_id = amt_volunteer_route.volunteer_id
          INNER JOIN route_street ON amt_volunteer_route.route_id = route_street.route_id
          INNER JOIN audit_task ON route_street.current_street_edge_id = audit_task.street_edge_id
              AND amt_volunteer_route.volunteer_id = audit_task.user_id
          INNER JOIN audit_task_interaction ON audit_task.audit_task_id = audit_task_interaction.audit_task_id
          WHERE action = \'ViewControl_MouseDown\'
              AND amt_condition_id NOT IN (71, 104, 105, 123, 124, 130, 138)
          ) user_audit_times
      WHERE diff < \'00:05:00.000\' AND diff > \'00:00:00.000\'
      GROUP BY user_audit_times.user_id;'
      )
  anon.times.turk.study <-
    dbGetQuery(
      db.connection.turk.study.production,
      'SELECT user_audit_times.user_id,
             CAST(extract( second from SUM(diff) ) / 60 +
                  extract( minute from SUM(diff) ) +
                  extract( hour from SUM(diff) ) * 60 AS decimal(10,2)) AS minutes_audited
      FROM
      (
          SELECT amt_volunteer_route.ip_address AS user_id,
                 (timestamp - LAG(timestamp, 1) OVER(PARTITION BY user_id ORDER BY timestamp)) AS diff
          FROM amt_condition
          INNER JOIN amt_volunteer_route ON amt_condition.volunteer_id = amt_volunteer_route.volunteer_id
          INNER JOIN route_street ON amt_volunteer_route.route_id = route_street.route_id
          INNER JOIN audit_task ON route_street.current_street_edge_id = audit_task.street_edge_id
          INNER JOIN audit_task_environment ON  audit_task.audit_task_id = audit_task_environment.audit_task_id
                                            AND amt_volunteer_route.ip_address = audit_task_environment.ip_address
          INNER JOIN audit_task_interaction ON audit_task.audit_task_id = audit_task_interaction.audit_task_id
          WHERE action = \'ViewControl_MouseDown\'
              AND amt_condition_id NOT IN (71, 104, 105, 123, 124, 130, 138)
          ) user_audit_times
      WHERE diff < \'00:05:00.000\' AND diff > \'00:00:00.000\'
      GROUP BY user_audit_times.user_id;'
      )
  turk.times.turk.study <-
    dbGetQuery(
      db.connection.turk.study,
      'SELECT user_audit_times.user_id,
             CAST(extract( second from SUM(diff) ) / 60 +
                  extract( minute from SUM(diff) ) +
                  extract( hour from SUM(diff) ) * 60 AS decimal(10,2)) AS minutes_audited
      FROM
      (
          SELECT turker_id AS user_id,
                 (timestamp - LAG(timestamp, 1) OVER(PARTITION BY user_id ORDER BY timestamp)) AS diff
          FROM amt_assignment
          INNER JOIN audit_task ON amt_assignment.amt_assignment_id = audit_task.amt_assignment_id
          INNER JOIN audit_task_interaction ON audit_task.audit_task_id = audit_task_interaction.audit_task_id
          WHERE action = \'ViewControl_MouseDown\'
              AND condition_id NOT IN (71, 104, 105, 123, 124, 130, 138)
          ) user_audit_times
      WHERE diff < \'00:05:00.000\' AND diff > \'00:00:00.000\'
      GROUP BY user_audit_times.user_id;'
      )
  dbDisconnect(db.connection.turk.study.production)
  dbDisconnect(db.connection.turk.study)
  
  # audits.turk.study <- bind_rows(reg.audits.turk.study, anon.audits.turk.study, turk.audits.turk.study)
  times.turk.study <- bind_rows(reg.times.turk.study, anon.times.turk.study, turk.times.turk.study)
  labels.turk.study <- bind_rows(reg.labels.turk.study, anon.labels.turk.study, turk.labels.turk.study)
  # sessions.turk.study <- bind_rows(reg.sessions.turk.study, anon.sessions.turk.study, turk.sessions.turk.study)
  # write.csv(audits.turk.study, '../data/stats_for_paper_audits-turk_study.csv', row.names = FALSE)
  write.csv(times.turk.study, '../data/stats_for_paper_times-turk_study.csv', row.names = FALSE)
  write.csv(labels.turk.study, '../data/stats_for_paper_labels-turk_study.csv', row.names = FALSE)
  # write.csv(sessions.turk.study, '../data/stats_for_paper_sessions-turk_study.csv', row.names = FALSE)
} else {
  # audit.classes.turk.study <- c('character', 'character', 'numeric', 'numeric', 'numeric')
  # audits.turk.study <- read.csv('../data/stats_for_paper_audits-turk_study.csv',
  #                               colClasses = audit.classes.turk.study)
  time.classes.turk.study <- c('character', 'numeric')
  times.turk.study <- read.csv('../data/stats_for_paper_times-turk_study.csv',
                               colClasses = time.classes.turk.study)
  label.classes.turk.study <- c('numeric', 'character', 'numeric', 'numeric', 'numeric')
  labels.turk.study <- read.csv('../data/stats_for_paper_labels-turk_study.csv',
                                colClasses = label.classes.turk.study)
  # session.classes.turk.study <- c('character', 'numeric')
  # sessions.turk.study <- read.csv('../data/stats_for_paper_sessions-turk_study.csv',
  #                                 colClasses = session.classes.turk.study)
}
```

```{r transforming.data, echo=FALSE, warning=FALSE}
# Takes a distance in feet and approximates the number of missions the user completed. The
# approximation assumes that the first missions are 500, 500, 1000, 2000, and 1280 feet, and all the
# remaining missions are half a mile (2640 feet).
approximate.missions.completed <- Vectorize(
  function(dist.in.feet) {
    if (dist.in.feet > 7920) 5 + floor((dist.in.feet - 5280) / 2640)
    else if (dist.in.feet > 5280) 5
    else if (dist.in.feet > 4000) 4
    else if (dist.in.feet > 2000) 3
    else if (dist.in.feet > 1000) 2
    else if (dist.in.feet > 500) 1
    else 0
  }
)

# Computes minutes_per_mission as either minutes_audited / missions_completed if at least one
# mission was completed, other wise 500 * minutes_audited / feet_audited (how long the first mission
# would take, given the auditing speed for what they had done)
approximate.minutes.per.mission <- Vectorize(
  function(time.audited, missions.completed, dist.in.feet) {
    if (missions.completed > 0) time.audited / missions.completed
    else 500 * time.audited / dist.in.feet
  }
)

label.counts <-
  labels %>%
  # filter(label_type_id != 7) %>%
  group_by(user_id) %>%
  summarize_at(vars(label_id), n_distinct) %>%
  rename(label_count = label_id)

# Selects distinct on audit_task_id, then sums dist audited.
audit.length <-
  audits %>%
  mutate(role = factor(role),
         role = recode(role, User = 'Registered', .default = levels(role))) %>%
  group_by(user_id, role) %>%
  distinct(audit_task_id, .keep_all = TRUE) %>%
  summarise(feet_audited = sum(feet_audited), audit_count = n()) %>%
  ungroup() %>%
  mutate(miles_audited = feet_audited / 5280) %>%
  left_join(label.counts, by = 'user_id') %>%
  replace_na(list(label_count = 0)) %>%
  left_join(sessions, by = 'user_id') %>%
  mutate(labels_per_100m = 328.084 * label_count / feet_audited)

# Computes approximate missions completed for anon users.
all.mission.counts <-
  audit.length %>%
  filter(role == "Anonymous") %>%
  mutate(mission_count = approximate.missions.completed(feet_audited)) %>%
  select(user_id, mission_count) %>%
  bind_rows(reg.missions)

# Computes a few metrics based on distance audited, time auditing, and missions completed.
speeds <-
  audit.length %>%
  left_join(all.mission.counts, by = 'user_id') %>%
  left_join(times, by = 'user_id') %>%
  mutate(feet_per_min = feet_audited / minutes_audited,
         minutes_per_mission = approximate.minutes.per.mission(minutes_audited, mission_count, feet_audited),
         minutes_per_1k_ft = 1000 * minutes_audited / feet_audited,
         hours_audited = minutes_audited / 60,
         minutes_per_session = minutes_audited / n_sessions)

filtered.speeds <-
  speeds %>%
  filter(role %in% c('Registered', 'Anonymous', 'Turker'),
         labels_per_100m >= 3.75)
```

## Public Deployment

NOTE: Public deployment data includes all data up through March 31st (and part of April 1st). This incldues all data through the most recent deployment on mturk.

### Top-line numbers (no filtering)

TODO: anything else?

```{r public.deployment.how.much.data, echo=FALSE, warning=FALSE}
kable(
  labels %>%
    distinct(label_id, .keep_all = TRUE) %>%
    count(label_type_id) %>%
    mutate(label_type = LABEL_TYPE_MAPPING[label_type_id]) %>%
    select(label_type, n) %>%
    bind_rows(list(label_type = 'Total', n = n_distinct(labels$label_id))) %>%
    spread(label_type, n),
  align = 'l'
)
```

### Data characteristics

This is the start of filtering out users with low labeling frequency (also filtering out researchers).

TODO: anything else?

```{r public.deployment.data.characteristics, echo=FALSE, warning=FALSE}
filtered.labels <- filter(labels, user_id %in% filtered.speeds$user_id)
kable(
  filtered.labels %>%
    distinct(label_id, .keep_all = TRUE) %>%
    count(label_type_id) %>%
    mutate(label_type = LABEL_TYPE_MAPPING[label_type_id]) %>%
    select(label_type, n) %>%
    bind_rows(list(label_type = 'Total', n = n_distinct(filtered.labels$label_id))) %>%
    spread(label_type, n),
  align = 'l'
)

filtered.audits <- filter(audits, user_id %in% filtered.speeds$user_id)
n.audits <- nrow(filtered.audits)
n.streets <- n_distinct(filtered.audits$street_edge_id)
```

There have been a total of `r n.audits` audits by our users across `r n.streets` streets, averaging `r format(n.audits/n.streets, digits = 3)` audits per street.

### User stats and tool usage

TODO: missions started vs missions completed (not sure we can do this; I expect that it would be difficult, without much benefit)

Below are the medians for a few metrics (followed by sums), split by user group. For all user groups, the minimum threshold to be included in this list was that they have completed at least one audit task and that their labeling threshold is above 3.75 labels per 100 meters.

```{r public.deployment.showing.stats, echo=FALSE, warning=FALSE}
kable(
  filtered.speeds %>%
    group_by(role) %>%
    summarise(
      n_users = n(),
      miles = median(miles_audited, na.rm = TRUE),
      missions = median(mission_count, na.rm = TRUE),
      audits = median(audit_count, na.rm = TRUE),
      minutes_audited = median(minutes_audited, na.rm = TRUE),
      minutes_per_1k_ft = median(minutes_per_1k_ft, na.rm = TRUE),
      labels = median(label_count, na.rm = TRUE),
      labels_per_100m = median(labels_per_100m, na.rm = TRUE),
      sessions = median(n_sessions, na.rm = TRUE),
      mins_per_sess = median(minutes_per_session, na.rm = TRUE)
      ),
  digits = 3,
  align = 'l'
  )

kable(
  filtered.speeds %>%
    group_by(role) %>%
    summarise(
      n_users = n(),
      miles = sum(miles_audited, na.rm = TRUE),
      coverage = paste0(format(100 * sum(miles_audited, na.rm = TRUE) / TOTAL_STREET_DIST_MILES,
                               digits = 2),
                        '%'),
      missions = sum(mission_count, na.rm = TRUE),
      audits = sum(audit_count, na.rm = TRUE),
      hours_audited = sum(hours_audited, na.rm = TRUE),
      labels = sum(label_count, na.rm = TRUE),
      '>1 sess' = paste0(format(100 * sum(n_sessions > 1) / n(), digits = 2), '%')
      ),
  digits = 3,
  align = 'l'
  )
```

### Possible Story 1: Data overlap and agreement between users

Amongst all the data collected in DC, how much of DC is labeled by multiple users and what is the disagreement amongst them? (see comment in Outline document for details on implementation)

## Turk Study

This is most of the data... I think there are just a couple "conditions" (i.e., "sets of routes") that were missing some amount of data in my local dump, so I need to investigate. I also think I may have failed to remove the conditions for anonymous users who didn't place any labels. So most of these numbers are trustworthy (though they aren't the *final* numbers), I would just be wary about drawing conclusions from the anonymous user data.

Also for the turkers' stats, this data is only looking at the first turker who completed each set of routes. I will be adding in the rest of the turkers at some point soon.

### High level results

```{r turk.reading.cleaning.data, echo=FALSE, include=FALSE}
classes <- c('numeric', replicate(5, 'character'), 'numeric', 'numeric', 'logical', 'logical',
             'numeric', 'factor', 'factor', replicate(8, 'numeric'))
volunteer.data <- read.csv('../data/accuracies-volunteer.csv',
                           colClasses = classes,
                           na.strings = c('null')) %>%
  mutate(is.turker = FALSE)
turker.data <- read.csv('../data/accuracies-turker.csv',
                        colClasses = classes,
                        na.strings = c('null')) %>%
  mutate(is.turker = TRUE)

# Combine datasets
accuracy.data <- rbind(volunteer.data, turker.data)

# Remove occlusion and other label types
accuracy.data <- subset(accuracy.data, !(label.type %in% c('Other', 'Occlusion')))
accuracy.data$label.type <- droplevels(accuracy.data$label.type)

# Rename SurfaceProblem label type as SurfaceProb for easier visualization
# possibly redo using https://stackoverflow.com/questions/28190435/changing-factor-levels-with-dplyr-mutate
label.type.levs <- levels(accuracy.data$label.type)
label.type.levs[6] <- c('SurfaceProb')
levels(accuracy.data$label.type) <- label.type.levs

# Reorder label type levels.
label.type.levs <- c('CurbRamp','NoCurbRamp','Obstacle','SurfaceProb', 'NoSidewalk','Problem')
accuracy.data$label.type <- factor(accuracy.data$label.type, label.type.levs)

# More setup: remove binary analysis (except street level), add is.anon.route column, add
#             raw.accuracy column, add worker.type column, give granularity an ordering.
get.worker.type <- Vectorize(
  function(n.workers, worker.thresh, is.turker, is.anon.route) {
    if (n.workers == 5 & worker.thresh == 3) 'maj'
    else if (is.turker == TRUE) 'turk'
    else if (is.anon.route == TRUE) 'anon'
    else 'reg'
  }
)
# The user.id column has the user id for reg and turk users, but for anon they are of the form
# '<anon.user.id>---<ip.address>'. Since the anon user id is the same for everyone, we just want the
# ip address. So this function splits on '---' (which only occurs for anon users), reverses the
# output of the split (meaning no ip address is now first in output list for anon users, and no
# change for other users, since the list is of length one), then takes first element of that list.
fix.anon.names <- Vectorize(
  function(user.id) {
    rev(strsplit(user.id, '---', fixed = TRUE)[[1]])[1]
  }
)
data.with.raw.accuracy <-
  accuracy.data %>%
  filter(granularity != '10_meter') %>%
  mutate(is.anon.route = condition.id > 121) %>%
  mutate(worker.type = factor(get.worker.type(n.workers, worker.thresh, is.turker, is.anon.route),
                              levels = c('anon', 'reg', 'turk', 'maj'))) %>%
  mutate(worker1 = fix.anon.names(worker1)) %>%
  mutate(raw.accuracy = (true.pos + true.neg) / (true.pos + true.neg + false.pos + false.neg)) %>%
  filter(label.type != 'NoSidewalk' | (granularity == 'street' & binary == TRUE))
```

TODO percentage of turkers who completed the HIT (maybe?) <br>
TODO anything else?

```{r turk.high.level.results, echo=FALSE, include=FALSE}
unique.turkers <-
  data.with.raw.accuracy %>%
  filter(n.workers == 5, worker.thresh == 3, !binary,
         !remove.low.severity, granularity == 'street', label.type == 'CurbRamp') %>%
  select(worker1, worker2, worker3, worker4, worker5) %>%
  gather(worker.index, turker.id) %>%
  select(turker.id)

n.turkers <- nrow(unique.turkers)
n.reg <- n_distinct(data.with.raw.accuracy %>% filter(!is.turker, !is.anon.route) %>% select(worker1))
n.anon <- n_distinct(data.with.raw.accuracy %>% filter(!is.turker, is.anon.route) %>% select(worker1))

# NOTE Multiply turker set by 5 if you want to count each turker who did each set of routes separately
turk.study.summary.stats <-
  data.with.raw.accuracy %>%
  filter(n.workers == 1, !binary, !remove.low.severity, granularity == 'street', label.type == 'CurbRamp') %>%
  left_join(labels.turk.study, by = c('worker1' = 'user_id', 'condition.id' = 'condition_id')) %>%
  group_by(worker1) %>%
  summarise(n.labels = n_distinct(label_id, na.rm = TRUE),
            is.anon.route = first(is.anon.route),
            worker.type = first(worker.type)) %>%
  left_join(times.turk.study, by = c('worker1' = 'user_id')) %>%
  mutate(n.missions = if_else(is.anon.route, 2, 3),
         distance.feet = if_else(is.anon.route, 2000, 4000),
         labels.per.100m = 100 * n.labels / (distance.feet / 3.28084),
         feet.per.min = distance.feet / minutes_audited,
         minutes.per.1k.ft = 1000 * minutes_audited / distance.feet,
         hours.audited = minutes_audited / 60)
         # minutes_per_session = minutes_audited / n_sessions)
```

A total of `r n.turkers` turkers, `r n.reg` registered users, and `r n.anon` anonymous users were part of this study.

Next we have average (median) stats, followed by aggregate (sum) stats.


```{r turk.showing.stats, echo=FALSE}
kable(
  turk.study.summary.stats %>%
    group_by(worker.type) %>%
    summarize(
      labels.per.100m = median(labels.per.100m, na.rm = TRUE),
      feet.per.min = median(feet.per.min, na.rm = TRUE),
      minutes.per.1k.ft = median(minutes.per.1k.ft, na.rm = TRUE),
      minutes_audited = median(minutes_audited, na.rm = TRUE)
    ),
  digits = 3,
  align = 'l'
  )

kable(
  turk.study.summary.stats %>%
    group_by(worker.type) %>%
    summarize(
      n.missions = sum(n.missions, na.rm = TRUE),
      distance.feet = sum(distance.feet, na.rm = TRUE),
      n.labels = sum(n.labels, na.rm = TRUE),
      hours.audited = sum(hours.audited, na.rm = TRUE)
    ) %>%
    mutate(distance.miles = distance.feet / 5280) %>%
    select(worker.type, n.missions, distance.miles, n.labels, hours.audited),
  digits = 3,
  align = 'l'
  )
```


### Possible Story 1: Street-level vs. 5 meter-level

For simplicity, the graphs below count only one true/false positie/negative per segment, instead of counting the number of labels in that segment. All user groups are also combined (the groups being: registered volunteers, anonymous volunteers, individual turkers, and 5 turkers with majority vote).

Note: The red dots on the graphs are means.

*Takeaways*:

* Analyzing at the 5 meter level shows higher raw accuracy and specificity, both because of the large number of true negatives that we get from splitting into 5 meter segments; there are very few street segments with no labels at all.

* Analyzing at the street level shows higher recall, implying that there were relatively fewer false negatives at the street level. This may mean that users aren't finding _every_ issue, but they are more likely to find _at least one_ issue of that type when there are multiple that occur on the same street.

* Analyzing at the street level shows higher precision, implying that there were relatively fewer false positives at the street level. I suspect that this is due to fundamental misunderstandings about how to label (implying both that labeling is complex and difficult and that our onboarding is insufficient) which are persistent/consistent and frequent (think: labeling driveways as curb ramps, labeling storm drains as missing curb ramps, and labeling fire hydrants or street signs that are not in the way as obstacles). In those cases where the mistake is made frequently (multiple times per street), relatively fewer false positives makes sense when moving to street level analysis.

* Analyzing at the street level shows higher f-measure. This clearly comes from the higher recall and precision.

* CurbRamp pretty much outperforms all other lable types across the board, regardless of accuracy type of 5 meter vs. street level. This is likely because curb ramps are the easiest label type to understand and find in GSV (both because they are large and easy to see, and because you know where to expect them -- at intersections).

* The SurfaceProblem label type seems to have the highest precision and lowest recall among the different types of issues (I'm excluding CurbRamp here). I guess that, relative to the other types of issues, there are just fewer cases of mistaking something of a surface problem and more cases of not finding a surface problem that was vsisible in GSV (so maybe surface problems require increased diligence from users, and the other issues require better treatment in onboarding).

* The Problem type seems to perform better than the surface problem and obstacle label types (except for surface problem precision, mentioned in the previous bullet).

* NoCurbRamp seems to have high recall and low precision. This fits my intuition; since users know to expect curb ramps at intersections, if they arrive at an intersection and a curb ramp is not there, they know to place a NoCurbRamp label. However, if there was no sidewalk at all, then we did not add the missing curb ramp labels to the ground truth dataset, and this is not something that we covered during onboarding. I suspect that this, paired with users marking storm drains as missing curb ramps, were the main reasons for the low recall. Both could be addressed through proper training.


```{r turk.granularity.analysis, echo=FALSE, fig.width=8, fig.height=6}
granularity.analysis.data <-
  data.with.raw.accuracy %>%
  filter(remove.low.severity == FALSE) %>%
  filter(binary == TRUE) %>%
  filter(n.workers == 1 | (n.workers == 5 & worker.thresh == 3)) %>%
  filter(label.type != 'NoSidewalk') %>%
  select(-specificity) %>%
  gather(accuracy.type, accuracy.value,
         recall, precision, f.measure, raw.accuracy,
         na.rm = TRUE, factor_key = TRUE)

# Create the trellis boxplot.
ggplot(data = granularity.analysis.data, aes(x = granularity, y = accuracy.value)) +
  geom_boxplot() +
  stat_summary(fun.y = mean, geom = 'point', color = 'red', size = 1) +
  facet_grid(accuracy.type ~ label.type) +
  ggtitle('Street vs. 5 Meter level Granularity') +
  my.theme.discrete.x
```


### Possible Story 2: Single vs. any number of issues per segment

For simplicity, the first graph looks at the 5 meter level, and the second looks at street level. All user groups are also combined (the groups being: registered volunteers, anonymous volunteers, individual turkers, and 5 turkers with majority vote).

Note: The red dots on the graphs are means.

*Takeaways*:

* 5 meter level (first graph): Considering multiple issues per segment results in _very slightly_ lower accuracy for pretty much every type of label and type of accuracy (except precision). I suspect that this comes mostly from our method of clustering, which makes it unlikely that users end up with multiple labels per 5 meter segment. We do not have this restriction in the ground truth, so those few cases where we have more than one label per 5 meter segment in the GT usually results in an additional false negative when moving to ordinal analysis. However, the difference here is very small, so our clustering method seems fine to me.

* Street level (second graph) recall: If we do this analysis at the street level, the decreases in accuracy are more pronounced. At this level, the clustering shouldn't have much effect. The decrease in recall suggests that users are finding _some_ of the problems, but not _all_ of them (meaning an increase in false negatives when we move to ordinal analysis).

* Street level (second graph) recall: I suspect that the reason for the decrease in precision when moving to ordinal analysis at the street level is the same reason as why 5 meter level has lower precision than street level (seen in the previous section). That is, users' misunderstandings of how to label certain common things (driveways as curb ramps, etc.); since these mistakes are common, they may happen many times on a single street edge, which means that you start racking up the false positives when you move to ordinal analysis.


```{r turk.issues.per.seg.analysis, echo=FALSE, fig.width=8, fig.height=6}
issues.per.seg.analysis.data <-
  data.with.raw.accuracy %>%
  filter(remove.low.severity == FALSE) %>%
  filter(n.workers == 1 | (n.workers == 5 & worker.thresh == 3)) %>%
  filter(label.type != 'NoSidewalk') %>%
  select(-specificity) %>%
  mutate(issues.per.segment = factor(if_else(binary, 'binary', 'ordinal'))) %>%
  gather(accuracy.type, accuracy.value,
         recall, precision, f.measure, raw.accuracy,
         na.rm = TRUE, factor_key = TRUE)

# Create the trellis boxplots.
ggplot(data = issues.per.seg.analysis.data %>% filter(granularity == '5_meter'),
       aes(x = issues.per.segment, y = accuracy.value)) +
  geom_boxplot() +
  stat_summary(fun.y = mean, geom = 'point', color = 'red', size = 1) +
  facet_grid(accuracy.type ~ label.type) +
  ggtitle('5 Meter-Level Analysis of Issues per Segment') +
  my.theme.discrete.x
ggplot(data = issues.per.seg.analysis.data %>% filter(granularity == 'street'),
       aes(x = issues.per.segment, y = accuracy.value)) +
  geom_boxplot() +
  stat_summary(fun.y = mean, geom = 'point', color = 'red', size = 1) +
  facet_grid(accuracy.type ~ label.type) +
  ggtitle('Street-Level Analysis of Issues per Segment') +
  my.theme.discrete.x
```

